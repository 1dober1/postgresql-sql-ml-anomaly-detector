import pandas as pd
import numpy as np
import pickle
import os
import sys
import json
import psycopg
import requests
from datetime import datetime, timezone
from dotenv import load_dotenv

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.append(os.path.abspath(os.path.join(BASE_DIR, '..')))
load_dotenv(os.path.join(BASE_DIR, '..', '.env'))

# –§–∞–π–ª, —á—Ç–æ–±—ã –ø–æ–º–Ω–∏—Ç—å —Å—á–µ—Ç—á–∏–∫ –º–µ–∂–¥—É –∑–∞–ø—É—Å–∫–∞–º–∏
STATE_FILE = os.path.join(BASE_DIR, "drift_state.json")
CONSECUTIVE_RUNS_LIMIT = 5  # –°–∫–æ–ª—å–∫–æ "–ø–ª–æ—Ö–∏—Ö" –∑–∞–ø—É—Å–∫–æ–≤ –ø–æ–¥—Ä—è–¥ –Ω—É–∂–Ω–æ –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è

try:
    from scripts.db_config import DB_CONFIG
    from scripts.train_model import train as train_model_emergency
except ImportError:
    # –§–æ–ª–±–µ–∫ –¥–ª—è –ø—Ä—è–º–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
    from db_config import DB_CONFIG
    from train_model import train as train_model_emergency

TG_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TG_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")
MODEL_FILENAME = "model_baseline_v1.pkl"
MODEL_VERSION = "baseline_v1"

# –ü—Ä–∏–∑–Ω–∞–∫–∏ (–¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å train_model.py)
LOG_FEATURES = ['shared_read_per_call', 'temp_read_per_call', 'ms_per_row']
OTHER_NUM_FEATURES = ['calls_per_sec', 'cache_miss_ratio', 'temp_share', 'read_blks_per_row', 'exec_time_per_call_ms', 'rows_per_call', 'wal_bytes_per_call']
LEX_FEATURES = ['query_len_norm_chars', 'num_tokens', 'num_joins', 'num_where', 'num_group_by', 'num_order_by', 'has_write', 'has_ddl']
ALL_FEATURES = LOG_FEATURES + OTHER_NUM_FEATURES + LEX_FEATURES

# --- –†–ê–ë–û–¢–ê –° –°–û–°–¢–û–Ø–ù–ò–ï–ú (–°–ß–ï–¢–ß–ò–ö) ---
def load_state():
    if not os.path.exists(STATE_FILE):
        return {"bad_runs_streak": 0}
    try:
        with open(STATE_FILE, 'r') as f:
            return json.load(f)
    except:
        return {"bad_runs_streak": 0}

def save_state(state):
    with open(STATE_FILE, 'w') as f:
        json.dump(state, f)

# --- –£–¢–ò–õ–ò–¢–´ ---
def send_telegram_msg(text):
    if not TG_TOKEN or not TG_CHAT_ID:
        print("‚ö†Ô∏è Telegram config missing") 
        return
    url = f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage"
    try:
        if len(text) > 4000: text = text[:4000] + "..."
        requests.post(url, data={"chat_id": TG_CHAT_ID, "text": text, "parse_mode": "HTML"})
    except Exception as e:
        print(f"‚ùå Failed to send Telegram: {e}")

def load_model():
    path = os.path.abspath(MODEL_FILENAME)
    if not os.path.exists(path):
        print("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞! –û–±—É—á–∞–µ–º –Ω–æ–≤—É—é...")
        train_model_emergency()
    with open(path, 'rb') as f:
        return pickle.load(f)

def get_unscored_data():
    conn_str = f"postgresql+psycopg://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}"
    # –ë–µ—Ä–µ–º –í–°–ï –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ –µ—â–µ –Ω–µ –æ—Ü–µ–Ω–µ–Ω—ã
    query = f"""
    SELECT v.*
    FROM monitoring.features_with_lex v
    LEFT JOIN monitoring.anomaly_scores s
      ON s.model_version = '{MODEL_VERSION}'
     AND s.window_end = v.window_end
     AND s.dbid = v.dbid AND s.userid = v.userid AND s.queryid = v.queryid
    WHERE s.window_end IS NULL
    ORDER BY v.window_end ASC
    LIMIT 2000; 
    """
    try:
        return pd.read_sql(query, conn_str)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ë–î: {e}")
        return pd.DataFrame()

def save_scores(df_results):
    query = """
    INSERT INTO monitoring.anomaly_scores (
        window_start, window_end, dbid, userid, queryid,
        model_version, anomaly_score, is_anomaly, reason, scored_at
    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
    ON CONFLICT (model_version, window_end, dbid, userid, queryid) DO NOTHING;
    """
    records = []
    now_ts = datetime.now(timezone.utc)
    for _, row in df_results.iterrows():
        records.append((
            row['window_start'], row['window_end'], row['dbid'], row['userid'], row['queryid'],
            MODEL_VERSION, float(row['anomaly_score']), bool(row['is_anomaly']),
            json.dumps(row.get('reason_json', {})), now_ts
        ))
    with psycopg.connect(**DB_CONFIG) as conn:
        with conn.cursor() as cur:
            cur.executemany(query, records)
            conn.commit()

def process_alerts(anomalies_df):
    SCORE_THRESHOLD = 0.0 
    alerts_sent = 0
    
    with psycopg.connect(**DB_CONFIG) as conn:
        with conn.cursor() as cur:
            for _, row in anomalies_df.iterrows():
                if row['anomaly_score'] > SCORE_THRESHOLD: continue

                qid = row['queryid']
                try:
                    cur.execute("SELECT query_text FROM monitoring.query_lex_features WHERE queryid = %s LIMIT 1", (qid,))
                    res = cur.fetchone()
                    query_text = res[0] if res else "TEXT NOT FOUND"
                except: query_text = "ERR"

                if "monitoring." in str(query_text).lower(): continue

                msg = (
                    f"üö® <b>ANOMALY DETECTED</b>\n"
                    f"<b>Score:</b> {row['anomaly_score']:.3f}\n"
                    f"SQL: <code>{str(query_text)[:200].replace('<','&lt;')}</code>" 
                )
                send_telegram_msg(msg)
                alerts_sent += 1
                
    return alerts_sent

# --- –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø ---
def detect():
    print(f"--- –ó–ê–ü–£–°–ö –î–ï–¢–ï–ö–¢–û–†–ê ({datetime.now().strftime('%H:%M:%S')}) ---")
    
    # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    new_df = get_unscored_data()
    if new_df.empty:
        print("üí§ –ù–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
        return

    print(f"üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(new_df)} –Ω–æ–≤—ã—Ö –æ–∫–æ–Ω...")
    
    # 2. –ü—Ä–µ–¥–∏–∫—Ç
    model = load_model()
    df_clean = new_df.copy()
    df_clean[ALL_FEATURES] = df_clean[ALL_FEATURES].fillna(0)
    
    X = df_clean[ALL_FEATURES]
    new_df['is_anomaly'] = (model.predict(X) == -1)
    new_df['anomaly_score'] = model.decision_function(X)
    
    # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ü–µ–Ω–∫–∏ –≤ –±–∞–∑—É
    save_scores(new_df)
    
    # 4. –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Å—á–µ—Ç—á–∏–∫–∞
    anomalies = new_df[new_df['is_anomaly'] == True]
    
    state = load_state()
    current_streak = state.get("bad_runs_streak", 0)
    
    if not anomalies.empty:
        # –í —ç—Ç–æ–º –∑–∞–ø—É—Å–∫–µ –ï–°–¢–¨ –∞–Ω–æ–º–∞–ª–∏–∏
        alerts_count = process_alerts(anomalies)
        
        if alerts_count > 0:
            current_streak += 1
            print(f"‚ö†Ô∏è  –í —ç—Ç–æ–º –∑–∞–ø—É—Å–∫–µ –Ω–∞–π–¥–µ–Ω—ã –∞–Ω–æ–º–∞–ª–∏–∏. Streak: {current_streak}/{CONSECUTIVE_RUNS_LIMIT}")
        else:
            # –ê–Ω–æ–º–∞–ª–∏–∏ –±—ã–ª–∏ —Å–∏—Å—Ç–µ–º–Ω—ã–µ (monitoring.), —Å—á–µ—Ç—á–∏–∫ –Ω–µ —Ç—Ä–æ–≥–∞–µ–º –∏–ª–∏ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º? 
            # –î–æ–ø—É—Å—Ç–∏–º, –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∞–ª–µ—Ä—Ç–æ–≤ –Ω–µ—Ç, —Ç–æ –∏ –ø–∞–Ω–∏–∫–∏ –Ω–µ—Ç.
            print("‚ÑπÔ∏è –ê–Ω–æ–º–∞–ª–∏–∏ —Ç–æ–ª—å–∫–æ —Å–∏—Å—Ç–µ–º–Ω—ã–µ, —Å—á–µ—Ç—á–∏–∫ –Ω–µ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º.")
            current_streak = 0 # –°–±—Ä–æ—Å, —Ç–∞–∫ –∫–∞–∫ –∞—Ç–∞–∫–∏ –Ω–µ—Ç
    else:
        # –í —ç—Ç–æ–º –∑–∞–ø—É—Å–∫–µ –í–°–Å –ß–ò–°–¢–û
        if current_streak > 0:
            print("‚úÖ –ù–∞–≥—Ä—É–∑–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–ª–∞—Å—å. –°–±—Ä–æ—Å —Å—á–µ—Ç—á–∏–∫–∞.")
        current_streak = 0

    # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏—è –î–†–ï–ô–§–ê
    if current_streak >= CONSECUTIVE_RUNS_LIMIT:
        print(f"üõë –î–†–ï–ô–§ –ü–û–î–¢–í–ï–†–ñ–î–ï–ù! ({current_streak} –∑–∞–ø—É—Å–∫–æ–≤ –ø–æ–¥—Ä—è–¥ —Å –∞–Ω–æ–º–∞–ª–∏—è–º–∏)")
        send_telegram_msg(f"üõë <b>SYSTEM DRIFT DETECTED</b>\n{current_streak} checks in a row failed.\nüîÑ Starting Retraining...")
        
        # –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
        train_model_emergency()
        
        # –°–±—Ä–æ—Å —Å—á–µ—Ç—á–∏–∫–∞ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        current_streak = 0
        send_telegram_msg("‚úÖ Model successfully retrained to new data.")

    # 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    state["bad_runs_streak"] = current_streak
    save_state(state)

if __name__ == "__main__":
    detect()